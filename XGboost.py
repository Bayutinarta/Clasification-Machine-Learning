# -*- coding: utf-8 -*-
"""Harmonisa2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j_0CBWYy5aHi49tMANcN3rbrcxIuwcXK
"""

import pandas as pd
import matplotlib.pyplot as plt

harmo_names = ['Datetime', 'Voltage', 'label', 'Current', 'Cos_teta', 'Power_faktor', 'Active_power', 'Reactive_power', 'Apparent_power', 
              'HI1', 'HI3', 'HI5', 'HI7', 'HI9', 'HI11', 'HI13', 'HI15', 'HI17', 'HI19', 'HI21', 'HI23', 'HI25', 'HI27', 'HI29', 'HI31']

harmo_data = pd.read_csv('data 3-1.csv', names = harmo_names)
harmo_df = pd.DataFrame(harmo_data)

harmo_data.head()

harmo_data['label'].unique()

# Import label encoder 
from sklearn import preprocessing 
  
# label_encoder object knows how to understand word labels. 
label_encoder = preprocessing.LabelEncoder() 
  
# Encode labels in column 'species'. 
harmo_data['label']= label_encoder.fit_transform(harmo_data['label'])
  
harmo_data['label'].unique()

from sklearn.model_selection import train_test_split

Y = harmo_df.loc[:,'label'].values
X = harmo_df.loc[:,'HI1':'HI31'].values


#we split the dataset into a test and training set
train_x, test_x, train_y, test_y = train_test_split(X,Y , test_size=0.3, random_state=0)

from sklearn import tree
clf = tree.DecisionTreeClassifier(max_depth=2)
clf = clf.fit(train_x, train_y)

import xgboost as xgb
from sklearn.metrics import accuracy_score

dtest = xgb.DMatrix(test_x, test_y, feature_names=harmo_names[9:25])
dtrain = xgb.DMatrix(train_x, train_y,feature_names=harmo_names[9:25])

param = {'max_depth': 6, 
         'learning_rate': 0.3, 
         'verbosity': 1, 
         'objective': 'multi:softmax', 
         'num_class': 16, 
         'eval_metric': 'merror'}

#eval_set = [(dtrain, 'train'), (dtest, 'test')]
evallist = [(dtrain, 'train'), (dtest, 'test')]

num_round = 10
bst = xgb.train(param, dtrain, num_round, evallist)

ypred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)
accuracy_score(test_y,ypred)

from sklearn.model_selection import GridSearchCV
PARAMETERS = {"max_depth":[2, 6, 12],
"learning_rate":[0.3, 0.1, 0.03],
"n_estimators":[100]}

#Initialise XGBoost Model
model = xgb.XGBClassifier(n_estimators=100, n_jobs=-1)
"""Initialise Grid Search Model to inherit from the XGBoost Model,
set the of cross validations to 3 per combination and use accuracy
to score the models."""
model_gs = GridSearchCV(model,param_grid=PARAMETERS,cv=3,scoring="accuracy")
#Fit the model as done previously
model_gs.fit(train_x,train_y)
print(model_gs.best_params_)

predictions = model_gs.predict(test_x)
print('Accuracy:',accuracy_score(test_y, predictions))

print("Accuracy: %.2f%%" % (accuracy_score(test_y, predictions) * 100.0))

'''import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import recall_score
mat = confusion_matrix(test_y, predictions)
sns.heatmap(mat.T, square=True , annot=True, fmt='d', cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('true class')
plt.ylabel('predicted class')
print(classification_report(test_y, predictions))

# Commented out IPython magic to ensure Python compatibility.
from pylab import rcParams
# %matplotlib inline
from matplotlib import rcParams
from matplotlib.cm import rainbow




def plot_correlation(harmo_data):
    
    plot correlation's matrix to explore dependency between features 
    
    # init figure size
    rcParams['figure.figsize'] = 15, 20
    fig = plt.figure()
    sns.heatmap(harmo_data.corr(), annot=True, fmt=".2f")
    plt.title('correlation map')
    plt.show()
    fig.savefig('corr.png')
# plot correlation & densities
plot_correlation(harmo_data)'''

import numpy as np

gp= np.array([[50.50,55.7,34.34,24.50,27.45,23.20,19.7,14.94,6.23,15.45,11.80,6,6.90,10.48,11.00,6.0]])
prediksi = model_gs.predict(gp)
print(prediksi)
#print(gp)
x="test"
print(x)
K = "Kipas"
if prediksi==[0]:
  print("B")
'''elif gp == [1] :
  print("BK")
elif gp == [2] :
  print("BP")
elif gp == [3] :
  print("BPK")
elif gp == [4] :
  print("H")
elif gp == [5] :
  print("HB")
elif gp == [6] :
  print("HBK")
elif gp == [7] :
  print("HBP")
elif gp == [8] :
  print("HK")
elif gp == [9] :
  print("HP")'''
if prediksi == [10] :
   print(K)
'''elif gp == [11] :
  print("KPBH")
elif gp == [12] :
  print("Kosong")
elif gp == [13] :
  print("P")
elif gp == [14] :
  print("PK")
elif gp == [15] :
  print("PKH")'''
'''else:
  print("Perangkat Tidak Terdaftar")'''

#Antares
import requests
while True:
        data = '\r\n{\r\n  "m2m:cin": {\r\n    "cnf": "message",\r\n    "con": "\r\n      {\r\n      \t \\"Perangkat\\": \\"'+ str(K)+'\\"\r\n}\r\n"\r\n}\r\n}'
        url = 'https://platform.antares.id:8443/~/antares-cse/antares-id/Identifikasi-Perangkat-Listrik/Identifikasi-XGBosst'
        headers = {'cache-control':'no-cache','content-type':'application/json;ty=4','x-m2m-origin':'305ca710e4ab05a2:ff1172460fd7068c'}
        r = requests.post(url,headers=headers,data=data)

'''fig, ax = plt.subplots(figsize=(10, 10))
xgb.plot_importance(bst,ax=ax)
plt.show()

fig, ax = plt.subplots(figsize=(30, 30))
xgb.plot_tree(bst, num_trees=4, ax=ax)
plt.show()'''